{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional Approach for Predicting Indoor Location Using WiFi Fingerprinting\n",
    "## Ha Vu Tran\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havut\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "# necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "# magic word for producing visualizations in notebook\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#Scoring Metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"challenge1.csv\")\n",
    "\n",
    "#Eleminate unvalid data\n",
    "df.drop(['Unnamed: 0', 'USERID', 'PHONEID', 'TIMESTAMP'], axis = 1, inplace=True)\n",
    "col = df.columns[0:520]\n",
    "for i in col:\n",
    "    df[i].fillna(0, inplace=True)\n",
    "df.dropna(subset=['LONGITUDE','LATITUDE', 'FLOOR', 'BUILDINGID' ], inplace=True)\n",
    "#one can use command trainingData.isnull().sum() to double check\n",
    "\n",
    "\n",
    "#Rescale signal strength data\n",
    "df.iloc[:, 0:520] = np.where(df.iloc[:, 0:520] <= 0, \n",
    "                        df.iloc[:, 0:520] + 105, \n",
    "                        df.iloc[:, 0:520] - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select input and output data\n",
    "def preprocess_data(df):  \n",
    "    global X\n",
    "    global y\n",
    "    X = df.drop(['LONGITUDE', 'LATITUDE', 'BUILDINGID','FLOOR'], axis=1)\n",
    "    y = df[['BUILDINGID', 'FLOOR']]\n",
    "    \n",
    "    \n",
    "    #create Dummies for the targets to feed into the model\n",
    "    y = pd.get_dummies(data=y, columns=['BUILDINGID', 'FLOOR'])\n",
    "    \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "def split_data(X, y):\n",
    "    global X_train\n",
    "    global X_test\n",
    "    global y_train\n",
    "    global y_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 42,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    # Show the results of the split\n",
    "    print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 13411 samples.\n",
      "Testing set has 5748 samples.\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_data(df)\n",
    "X_train, X_test, y_train, y_test = split_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data with Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit only the training set\n",
    "scaler.fit(X_train)\n",
    "    \n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA Components = 469.\n",
      "Total Variance Explained by PCA Components = 0.9503886620587898.\n"
     ]
    }
   ],
   "source": [
    "#Apply PCA while keeping 95% of the variation in the data\n",
    "pca = PCA(.95)\n",
    "\n",
    "#Fit only the training set    \n",
    "pca.fit(X_train)\n",
    "\n",
    "# Apply PCA transform to both the training set and the test set.    \n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"Number of PCA Components = {}.\".format(pca.n_components_))\n",
    "#print(pca.n_components_)\n",
    "print(\"Total Variance Explained by PCA Components = {}.\".format(pca.explained_variance_ratio_.sum()))\n",
    "#print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sparse matrices to run the scikit multilearn algorithms\n",
    "X_train_pca = lil_matrix(X_train_pca).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "X_test_pca = lil_matrix(X_test_pca).toarray()\n",
    "y_test = lil_matrix(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.4145789839944328\n",
      "--- Run time: 2.15 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "MLKNN_classifier = MLkNN(k=1)\n",
    "\n",
    "MLKNN_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# predict mlknn =3\n",
    "predictions = MLKNN_classifier.predict(X_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6485734168406402\n",
      "--- Run time: 0.72 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "DecisionTree_classifier = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# train\n",
    "DecisionTree_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# predict \n",
    "predictions = DecisionTree_classifier.predict(X_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.22860125260960334\n",
      "--- Run time: 1.74 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RandomForest_classifier = RandomForestClassifier(n_estimators = 100, random_state=0)\n",
    "\n",
    "# train\n",
    "RandomForest_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# predict \n",
    "predictions = RandomForest_classifier.predict(X_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
