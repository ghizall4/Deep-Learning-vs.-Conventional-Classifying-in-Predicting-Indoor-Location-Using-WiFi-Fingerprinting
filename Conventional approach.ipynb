{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Conventional Approach for Predicting Indoor Location Using WiFi Fingerprinting\nHa Vu Tran       "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "markdown"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#!pip install scikit-multilearn\n",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# necessary Libraries\nimport numpy as np\nimport pandas as pd\nimport time\nimport pprint\n\n#Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n#Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA \nfrom scipy.sparse import lil_matrix\n\n#Models\nfrom sklearn.naive_bayes import GaussianNB\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom skmultilearn.problem_transform import ClassifierChain\nfrom skmultilearn.problem_transform import LabelPowerset\nfrom skmultilearn.adapt import MLkNN\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n#Scoring Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\n\n\n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Preprocess data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_csv(\"challenge1.csv\")\n\n#Eleminate unvalid data\ndf.drop(['Unnamed: 0', 'USERID', 'PHONEID', 'TIMESTAMP'], axis = 1, inplace=True)\ncol = df.columns[0:520]\nfor i in col:\n    df[i].fillna(0, inplace=True)\ndf.dropna(subset=['LONGITUDE','LATITUDE', 'FLOOR', 'BUILDINGID' ], inplace=True)\n#one can use command trainingData.isnull().sum() to double check\n\n\n#Rescale signal strength data\ndf.iloc[:, 0:520] = np.where(df.iloc[:, 0:520] <= 0, \n                        df.iloc[:, 0:520] + 105, \n                        df.iloc[:, 0:520] - 100)\n\n#Process Longtitude\ndf.iloc[:, 520] = np.where(df.iloc[:, 520] <= 0, \n                        -df.iloc[:, 520], \n                        df.iloc[:, 520])\n\nmin_LGT = 7300.818990\nmin_LAT = 4.864746e+06\n\ndf.iloc[:,520] = (df.iloc[:, 520] - min_LGT + 1)\ndf.iloc[:,521] = (df.iloc[:, 521] - min_LAT + 1)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Select input and output data\ndef preprocess_data(df):  \n\n    X = df.drop(['LONGITUDE', 'LATITUDE', 'BUILDINGID','FLOOR'], axis=1)\n    y = df[['BUILDINGID', 'FLOOR']]\n    \n    Z = df.drop(['LONGITUDE', 'LATITUDE', 'BUILDINGID','FLOOR'], axis=1)\n    v = df[['LONGITUDE', 'LATITUDE']]\n    \n    #create Dummies for the targets to feed into the model\n    y = pd.get_dummies(data=y, columns=['BUILDINGID', 'FLOOR'])\n    \n    \n    return X, y, Z, v",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Split data into training and testing sets\ndef split_data(X, y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, \n                                                        y, \n                                                        test_size = 0.1, \n                                                        random_state = 42,\n                                                        shuffle=True)\n\n    # Show the results of the split\n    print(\"Training set has {} samples.\".format(X_train.shape[0]))\n    print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n    return X_train, X_test, y_train, y_test",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X, y, Z, v = preprocess_data(df)\nX_train, X_test, y_train, y_test = split_data(X,y)\nZ_train, Z_test, v_train, v_test = split_data(Z,v)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training set has 17243 samples.\nTesting set has 1916 samples.\nTraining set has 17243 samples.\nTesting set has 1916 samples.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Scale Data with Standard Scaler\nscaler = StandardScaler()\n\n#Fit only the training set\nscaler.fit(X_train)\n    \n# Apply transform to both the training set and the test set.\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Apply transform to both the training set and the test set.\nZ_train = scaler.transform(Z_train)\nZ_test = scaler.transform(Z_test)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Apply PCA while keeping 95% of the variation in the data\npca = PCA(.95)\n\n#Fit only the training set    \npca.fit(X_train)\n\n# Apply PCA transform to both the training set and the test set.    \nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\nZ_train_pca = pca.transform(Z_train)\nZ_test_pca = pca.transform(Z_test)\n\nprint(\"Number of PCA Components = {}.\".format(pca.n_components_))\n#print(pca.n_components_)\nprint(\"Total Variance Explained by PCA Components = {}.\".format(pca.explained_variance_ratio_.sum()))\n#print(pca.explained_variance_ratio_.sum())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Number of PCA Components = 470.\nTotal Variance Explained by PCA Components = 0.9502160510907495.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Create sparse matrices to run the scikit multilearn algorithms\nX_train_pca = lil_matrix(X_train_pca).toarray()\ny_train = lil_matrix(y_train).toarray()\nX_test_pca = lil_matrix(X_test_pca).toarray()\ny_test = lil_matrix(y_test).toarray()\n\n#Create sparse matrices to run the scikit multilearn algorithms\nZ_train_pca = lil_matrix(Z_train_pca).toarray()\nv_train = lil_matrix(v_train).toarray()\nZ_test_pca = lil_matrix(Z_test_pca).toarray()\nv_test = lil_matrix(v_test).toarray()",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Training and Checking Accuracy"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Predicting Building and Floor"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()\n\nMLKNN_classifier = MLkNN(k=1)\n\nMLKNN_classifier.fit(X_train_pca, y_train)\n\n# predict mlknn =3\npredictions = MLKNN_classifier.predict(X_test_pca)\n\n# accuracy\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\n\nprint(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy =  0.42275574112734865\n--- Run time: 1.45 mins ---\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()\n\nDecisionTree_classifier = DecisionTreeClassifier(random_state=0)\n\n# train\nDecisionTree_classifier.fit(X_train_pca, y_train)\n\n# predict \npredictions = DecisionTree_classifier.predict(X_test_pca)\n\n# accuracy\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\n\nprint(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy =  0.668580375782881\n--- Run time: 0.64 mins ---\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()\n\nRandomForest_classifier = RandomForestClassifier(n_estimators = 100, random_state=0)\n\n# train\nRandomForest_classifier.fit(X_train_pca, y_train)\n\n# predict \npredictions = RandomForest_classifier.predict(X_test_pca)\n\n# accuracy\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\n\nprint(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy =  0.27713987473903967\n--- Run time: 1.66 mins ---\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Predicting Longitude and Latitude"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using decision tree"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()\n\nDecisionTree_Regressor = DecisionTreeRegressor(random_state=0)\n\n# train\nDecisionTree_Regressor.fit(Z_train_pca, v_train)\n\n# predict \npredictions = DecisionTree_Regressor.predict(Z_test_pca)\n\n# accuracy\nprint(\"RMSE of predicting LONGTITUDE = \", mean_squared_error(v_test[:,0],predictions[:,0])**(0.5))\nprint(\"RMSE of predicting LATITUDE = \", mean_squared_error(v_test[:,1],predictions[:,1])**(0.5))\n\n\nprint(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RMSE of predicting LONGTITUDE =  46.55169957879674\nRMSE of predicting LATITUDE =  28.27677954213633\n--- Run time: 0.36 mins ---\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using random forest"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()\n\nRandomForest_Regressor = RandomForestRegressor(n_estimators = 100, random_state=0)\n\n# train\nRandomForest_Regressor.fit(Z_train_pca, v_train)\n\n# predict \npredictions = RandomForest_Regressor.predict(Z_test_pca)\n\n# accuracy\nprint(\"RMSE of predicting LONGTITUDE = \", mean_squared_error(v_test[:,0],predictions[:,0])**(0.5))\nprint(\"RMSE of predicting LATITUDE = \", mean_squared_error(v_test[:,1],predictions[:,1])**(0.5))\n\n\nprint(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RMSE of predicting LONGTITUDE =  31.69892418328501\nRMSE of predicting LATITUDE =  19.922173923651574\n--- Run time: 19.43 mins ---\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}