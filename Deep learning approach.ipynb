{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Predicting Indoor Location Using WiFi Fingerprinting\n",
    "Ha Vu Tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havut\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "#Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "# magic word for producing visualizations in notebook\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "#Scoring Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"challenge1.csv\")\n",
    "\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP514</th>\n",
       "      <th>WAP515</th>\n",
       "      <th>WAP516</th>\n",
       "      <th>WAP517</th>\n",
       "      <th>WAP518</th>\n",
       "      <th>WAP519</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>BUILDINGID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19159.00000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.00000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>19159.000000</td>\n",
       "      <td>1.915900e+04</td>\n",
       "      <td>19159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.951720</td>\n",
       "      <td>0.965082</td>\n",
       "      <td>1.145415</td>\n",
       "      <td>1.150895</td>\n",
       "      <td>0.979644</td>\n",
       "      <td>1.396263</td>\n",
       "      <td>1.750822</td>\n",
       "      <td>1.821859</td>\n",
       "      <td>1.907198</td>\n",
       "      <td>1.182891</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13889</td>\n",
       "      <td>1.103868</td>\n",
       "      <td>5.919202</td>\n",
       "      <td>7.535832</td>\n",
       "      <td>1.15340</td>\n",
       "      <td>1.048176</td>\n",
       "      <td>1.161856</td>\n",
       "      <td>7464.202052</td>\n",
       "      <td>4.864871e+06</td>\n",
       "      <td>1.213581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.907839</td>\n",
       "      <td>9.945870</td>\n",
       "      <td>10.907006</td>\n",
       "      <td>10.932780</td>\n",
       "      <td>9.975353</td>\n",
       "      <td>10.995386</td>\n",
       "      <td>11.424759</td>\n",
       "      <td>11.274403</td>\n",
       "      <td>11.739711</td>\n",
       "      <td>10.859246</td>\n",
       "      <td>...</td>\n",
       "      <td>10.38636</td>\n",
       "      <td>10.499751</td>\n",
       "      <td>16.221807</td>\n",
       "      <td>16.427428</td>\n",
       "      <td>10.88876</td>\n",
       "      <td>10.432185</td>\n",
       "      <td>10.984137</td>\n",
       "      <td>123.311468</td>\n",
       "      <td>6.696052e+01</td>\n",
       "      <td>0.832702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7300.818990</td>\n",
       "      <td>4.864746e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7359.148500</td>\n",
       "      <td>4.864821e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7423.060900</td>\n",
       "      <td>4.864852e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7594.264100</td>\n",
       "      <td>4.864930e+06</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>7691.338400</td>\n",
       "      <td>4.865017e+06</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WAP001        WAP002        WAP003        WAP004        WAP005  \\\n",
       "count  19159.000000  19159.000000  19159.000000  19159.000000  19159.000000   \n",
       "mean       0.951720      0.965082      1.145415      1.150895      0.979644   \n",
       "std        9.907839      9.945870     10.907006     10.932780      9.975353   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      105.000000    105.000000    105.000000    105.000000    105.000000   \n",
       "\n",
       "             WAP006        WAP007        WAP008        WAP009        WAP010  \\\n",
       "count  19159.000000  19159.000000  19159.000000  19159.000000  19159.000000   \n",
       "mean       1.396263      1.750822      1.821859      1.907198      1.182891   \n",
       "std       10.995386     11.424759     11.274403     11.739711     10.859246   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      105.000000    105.000000    105.000000    105.000000    105.000000   \n",
       "\n",
       "           ...            WAP514        WAP515        WAP516        WAP517  \\\n",
       "count      ...       19159.00000  19159.000000  19159.000000  19159.000000   \n",
       "mean       ...           1.13889      1.103868      5.919202      7.535832   \n",
       "std        ...          10.38636     10.499751     16.221807     16.427428   \n",
       "min        ...           0.00000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.00000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.00000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.00000      0.000000      0.000000      0.000000   \n",
       "max        ...         105.00000    105.000000    105.000000    105.000000   \n",
       "\n",
       "            WAP518        WAP519        WAP520     LONGITUDE      LATITUDE  \\\n",
       "count  19159.00000  19159.000000  19159.000000  19159.000000  1.915900e+04   \n",
       "mean       1.15340      1.048176      1.161856   7464.202052  4.864871e+06   \n",
       "std       10.88876     10.432185     10.984137    123.311468  6.696052e+01   \n",
       "min        0.00000      0.000000      0.000000   7300.818990  4.864746e+06   \n",
       "25%        0.00000      0.000000      0.000000   7359.148500  4.864821e+06   \n",
       "50%        0.00000      0.000000      0.000000   7423.060900  4.864852e+06   \n",
       "75%        0.00000      0.000000      0.000000   7594.264100  4.864930e+06   \n",
       "max      105.00000    105.000000    105.000000   7691.338400  4.865017e+06   \n",
       "\n",
       "         BUILDINGID  \n",
       "count  19159.000000  \n",
       "mean       1.213581  \n",
       "std        0.832702  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        2.000000  \n",
       "max        2.000000  \n",
       "\n",
       "[8 rows x 523 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Drop unneeded data\n",
    "df.drop(['Unnamed: 0', 'USERID', 'PHONEID', 'TIMESTAMP'], axis = 1, inplace=True)\n",
    "\n",
    "#Remove \"NaN\" value\n",
    "col = df.columns[0:520]\n",
    "for i in col:\n",
    "    df[i].fillna(0, inplace=True)\n",
    "df.dropna(subset=['LONGITUDE','LATITUDE', 'FLOOR', 'BUILDINGID' ], inplace=True)\n",
    "#trainingData.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "#Process \"WAP\" data\n",
    "df.iloc[:, 0:520] = np.where(df.iloc[:, 0:520] <= 0, \n",
    "                        df.iloc[:, 0:520] + 105, \n",
    "                        df.iloc[:, 0:520] - 100)\n",
    "\n",
    "#Process Longtitude\n",
    "df.iloc[:, 520] = np.where(df.iloc[:, 520] <= 0, \n",
    "                        -df.iloc[:, 520], \n",
    "                        df.iloc[:, 520])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_LGT = 7300.818990\n",
    "min_LAT = 4.864746e+06\n",
    "\n",
    "df.iloc[:,520] = (df.iloc[:, 520] - min_LGT + 10)/1000\n",
    "df.iloc[:,521] = (df.iloc[:, 521] - min_LAT + 10)/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Separates trainingData into Features and Targets\n",
    "    Will also be applied to validationData\n",
    "    \n",
    "    INPUT: Cleaned trainingData DataFrame\n",
    "    OUTPUT: trainingData as Features and Targets\n",
    "    \"\"\"\n",
    "    \n",
    "    global X1\n",
    "    global y1\n",
    "    global X2\n",
    "    global y2\n",
    "    global X3\n",
    "    global y3\n",
    "    \n",
    "    # split the data set into features and targets(Floor and BuildingID)\n",
    "    X1 = df.drop(['LONGITUDE', 'LATITUDE', 'BUILDINGID','FLOOR'], axis=1)\n",
    "    y1 = df[[ 'BUILDINGID']]\n",
    "    \n",
    "    X2 = df.drop(['LONGITUDE', 'LATITUDE','FLOOR'], axis=1)\n",
    "    y2 = df[['FLOOR']]\n",
    "    \n",
    "    \n",
    "    X3 = df.drop(['LONGITUDE', 'LATITUDE','FLOOR'], axis=1)\n",
    "    y3 = df[[ 'LONGITUDE']]\n",
    "    \n",
    "    #create Dummies for the targets to feed into the model\n",
    "    y1 = pd.get_dummies(data=y1, columns=[ 'BUILDINGID'])\n",
    "    y2 = pd.get_dummies(data=y2, columns=[ 'FLOOR']) \n",
    "    X3 = pd.get_dummies(data=X3, columns=['BUILDINGID']) \n",
    "    \n",
    "    return X1, y1, X2, y2, X3, y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "# TO AVOID OVERFITTING: Split the training data into training and testing sets \n",
    "    global X_train\n",
    "    global X_test\n",
    "    global y_train\n",
    "    global y_test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = 0.3, \n",
    "                                                        random_state = 42,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "    # Show the results of the split\n",
    "    print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "    print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 13411 samples.\n",
      "Testing set has 5748 samples.\n",
      "Training set has 13411 samples.\n",
      "Testing set has 5748 samples.\n",
      "Training set has 13411 samples.\n",
      "Testing set has 5748 samples.\n"
     ]
    }
   ],
   "source": [
    "X1, y1, X2, y2, X3, y3 = preprocess_data(df)\n",
    "X_train1, X_test1, y_train1, y_test1 = split_data(X1,y1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_data(X2,y2)\n",
    "X_train3, X_test3, y_train3, y_test3 = split_data(X3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data with Standard Scaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "scaler1.fit(X_train1)\n",
    "    \n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train1 = scaler1.transform(X_train1)\n",
    "X_test1 = scaler1.transform(X_test1)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(X_train2)\n",
    "    \n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train2 = scaler2.transform(X_train2)\n",
    "X_test2 = scaler2.transform(X_test2)\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(X_train3)\n",
    "    \n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train3 = scaler3.transform(X_train3)\n",
    "X_test3 = scaler3.transform(X_test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = lil_matrix(y_train1).toarray()\n",
    "y_test1 = lil_matrix(y_test1).toarray()\n",
    "y_train2 = lil_matrix(y_train2).toarray()\n",
    "y_test2 = lil_matrix(y_test2).toarray()\n",
    "y_train3 = lil_matrix(y_train3).toarray()\n",
    "y_test3 = lil_matrix(y_test3).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " - 2s - loss: 0.1184\n",
      "Epoch 2/70\n",
      " - 1s - loss: 0.0233\n",
      "Epoch 3/70\n",
      " - 1s - loss: 0.0077\n",
      "Epoch 4/70\n",
      " - 1s - loss: 0.0020\n",
      "Epoch 5/70\n",
      " - 1s - loss: 5.1251e-04\n",
      "Epoch 6/70\n",
      " - 1s - loss: 1.8397e-04\n",
      "Epoch 7/70\n",
      " - 1s - loss: 7.8302e-05\n",
      "Epoch 8/70\n",
      " - 1s - loss: 4.1393e-05\n",
      "Epoch 9/70\n",
      " - 1s - loss: 2.7416e-05\n",
      "Epoch 10/70\n",
      " - 1s - loss: 1.9206e-05\n",
      "Epoch 11/70\n",
      " - 1s - loss: 1.3813e-05\n",
      "Epoch 12/70\n",
      " - 1s - loss: 1.0253e-05\n",
      "Epoch 13/70\n",
      " - 1s - loss: 7.5874e-06\n",
      "Epoch 14/70\n",
      " - 1s - loss: 5.7467e-06\n",
      "Epoch 15/70\n",
      " - 1s - loss: 4.3924e-06\n",
      "Epoch 16/70\n",
      " - 1s - loss: 3.3827e-06\n",
      "Epoch 17/70\n",
      " - 1s - loss: 2.6166e-06\n",
      "Epoch 18/70\n",
      " - 1s - loss: 2.0319e-06\n",
      "Epoch 19/70\n",
      " - 1s - loss: 1.5768e-06\n",
      "Epoch 20/70\n",
      " - 1s - loss: 1.2323e-06\n",
      "Epoch 21/70\n",
      " - 1s - loss: 9.7495e-07\n",
      "Epoch 22/70\n",
      " - 1s - loss: 7.7370e-07\n",
      "Epoch 23/70\n",
      " - 1s - loss: 6.2623e-07\n",
      "Epoch 24/70\n",
      " - 1s - loss: 5.0832e-07\n",
      "Epoch 25/70\n",
      " - 1s - loss: 4.1790e-07\n",
      "Epoch 26/70\n",
      " - 1s - loss: 3.4780e-07\n",
      "Epoch 27/70\n",
      " - 1s - loss: 2.9307e-07\n",
      "Epoch 28/70\n",
      " - 1s - loss: 2.5171e-07\n",
      "Epoch 29/70\n",
      " - 1s - loss: 2.1924e-07\n",
      "Epoch 30/70\n",
      " - 1s - loss: 1.9401e-07\n",
      "Epoch 31/70\n",
      " - 1s - loss: 1.7406e-07\n",
      "Epoch 32/70\n",
      " - 1s - loss: 1.5850e-07\n",
      "Epoch 33/70\n",
      " - 1s - loss: 1.4674e-07\n",
      "Epoch 34/70\n",
      " - 1s - loss: 1.3712e-07\n",
      "Epoch 35/70\n",
      " - 1s - loss: 1.2980e-07\n",
      "Epoch 36/70\n",
      " - 1s - loss: 1.2409e-07\n",
      "Epoch 37/70\n",
      " - 1s - loss: 1.1967e-07\n",
      "Epoch 38/70\n",
      " - 1s - loss: 1.1626e-07\n",
      "Epoch 39/70\n",
      " - 1s - loss: 1.1371e-07\n",
      "Epoch 40/70\n",
      " - 1s - loss: 1.1167e-07\n",
      "Epoch 41/70\n",
      " - 1s - loss: 1.1024e-07\n",
      "Epoch 42/70\n",
      " - 1s - loss: 1.0911e-07\n",
      "Epoch 43/70\n",
      " - 1s - loss: 1.0833e-07\n",
      "Epoch 44/70\n",
      " - 1s - loss: 1.0775e-07\n",
      "Epoch 45/70\n",
      " - 1s - loss: 1.0733e-07\n",
      "Epoch 46/70\n",
      " - 1s - loss: 1.0707e-07\n",
      "Epoch 47/70\n",
      " - 1s - loss: 1.0686e-07\n",
      "Epoch 48/70\n",
      " - 1s - loss: 1.0673e-07\n",
      "Epoch 49/70\n",
      " - 1s - loss: 1.0666e-07\n",
      "Epoch 50/70\n",
      " - 1s - loss: 1.0658e-07\n",
      "Epoch 51/70\n",
      " - 1s - loss: 1.0655e-07\n",
      "Epoch 52/70\n",
      " - 1s - loss: 1.0650e-07\n",
      "Epoch 53/70\n",
      " - 1s - loss: 1.0648e-07\n",
      "Epoch 54/70\n",
      " - 1s - loss: 1.0646e-07\n",
      "Epoch 55/70\n",
      " - 1s - loss: 1.0645e-07\n",
      "Epoch 56/70\n",
      " - 1s - loss: 1.0644e-07\n",
      "Epoch 57/70\n",
      " - 1s - loss: 1.0643e-07\n",
      "Epoch 58/70\n",
      " - 1s - loss: 1.0643e-07\n",
      "Epoch 59/70\n",
      " - 1s - loss: 1.0642e-07\n",
      "Epoch 60/70\n",
      " - 1s - loss: 1.0642e-07\n",
      "Epoch 61/70\n",
      " - 1s - loss: 1.0641e-07\n",
      "Epoch 62/70\n",
      " - 1s - loss: 1.0641e-07\n",
      "Epoch 63/70\n",
      " - 1s - loss: 1.0641e-07\n",
      "Epoch 64/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Epoch 65/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Epoch 66/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Epoch 67/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Epoch 68/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Epoch 69/70\n",
      " - 2s - loss: 1.0640e-07\n",
      "Epoch 70/70\n",
      " - 1s - loss: 1.0640e-07\n",
      "Accuracy of predicting buildings =  0.9678148921363953\n",
      "--- Run time: 1.52 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, input_dim=520, activation='relu'))\n",
    "model_1.add(Dense(80, activation='relu'))\n",
    "model_1.add(Dense(50, activation='relu'))\n",
    "model_1.add(Dense(3, activation='softmax'))\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(\n",
    "    X_train1,\n",
    "    y_train1,\n",
    "    epochs=70,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "predictions1 = np.round(model_1.predict(X_test1))\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy of predicting buildings = \",accuracy_score(y_test1,predictions1))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 2s - loss: 0.2926\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1516\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0954\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0600\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0347\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0214\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0125\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0150\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0157\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.0163\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0090\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.0043\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0029\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.0022\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.0043\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0169\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0168\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0084\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0028\n",
      "Epoch 20/100\n",
      " - 1s - loss: 9.5103e-04\n",
      "Epoch 21/100\n",
      " - 1s - loss: 4.5170e-04\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0013\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.0056\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0160\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0080\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0043\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0026\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0018\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.0023\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0026\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0094\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0099\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0082\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.0043\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.0018\n",
      "Epoch 36/100\n",
      " - 1s - loss: 4.8324e-04\n",
      "Epoch 37/100\n",
      " - 1s - loss: 7.4521e-05\n",
      "Epoch 38/100\n",
      " - 1s - loss: 4.3818e-05\n",
      "Epoch 39/100\n",
      " - 1s - loss: 3.0823e-05\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.3943e-05\n",
      "Epoch 41/100\n",
      " - 1s - loss: 1.8839e-05\n",
      "Epoch 42/100\n",
      " - 1s - loss: 1.4962e-05\n",
      "Epoch 43/100\n",
      " - 1s - loss: 1.1928e-05\n",
      "Epoch 44/100\n",
      " - 1s - loss: 9.5576e-06\n",
      "Epoch 45/100\n",
      " - 1s - loss: 7.6515e-06\n",
      "Epoch 46/100\n",
      " - 1s - loss: 6.1465e-06\n",
      "Epoch 47/100\n",
      " - 1s - loss: 4.9392e-06\n",
      "Epoch 48/100\n",
      " - 1s - loss: 3.9748e-06\n",
      "Epoch 49/100\n",
      " - 1s - loss: 3.2004e-06\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.5790e-06\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.0884e-06\n",
      "Epoch 52/100\n",
      " - 1s - loss: 1.6951e-06\n",
      "Epoch 53/100\n",
      " - 1s - loss: 1.3732e-06\n",
      "Epoch 54/100\n",
      " - 1s - loss: 1.1203e-06\n",
      "Epoch 55/100\n",
      " - 1s - loss: 9.1373e-07\n",
      "Epoch 56/100\n",
      " - 1s - loss: 7.5045e-07\n",
      "Epoch 57/100\n",
      " - 1s - loss: 6.1958e-07\n",
      "Epoch 58/100\n",
      " - 1s - loss: 5.1399e-07\n",
      "Epoch 59/100\n",
      " - 1s - loss: 4.2994e-07\n",
      "Epoch 60/100\n",
      " - 1s - loss: 3.6262e-07\n",
      "Epoch 61/100\n",
      " - 1s - loss: 3.0866e-07\n",
      "Epoch 62/100\n",
      " - 1s - loss: 2.6593e-07\n",
      "Epoch 63/100\n",
      " - 1s - loss: 2.3203e-07\n",
      "Epoch 64/100\n",
      " - 1s - loss: 2.0495e-07\n",
      "Epoch 65/100\n",
      " - 1s - loss: 1.8304e-07\n",
      "Epoch 66/100\n",
      " - 1s - loss: 1.6617e-07\n",
      "Epoch 67/100\n",
      " - 1s - loss: 1.5250e-07\n",
      "Epoch 68/100\n",
      " - 1s - loss: 1.4167e-07\n",
      "Epoch 69/100\n",
      " - 1s - loss: 1.3311e-07\n",
      "Epoch 70/100\n",
      " - 1s - loss: 1.2636e-07\n",
      "Epoch 71/100\n",
      " - 1s - loss: 1.2111e-07\n",
      "Epoch 72/100\n",
      " - 1s - loss: 1.1695e-07\n",
      "Epoch 73/100\n",
      " - 1s - loss: 1.1372e-07\n",
      "Epoch 74/100\n",
      " - 1s - loss: 1.1118e-07\n",
      "Epoch 75/100\n",
      " - 1s - loss: 1.0928e-07\n",
      "Epoch 76/100\n",
      " - 1s - loss: 1.0778e-07\n",
      "Epoch 77/100\n",
      " - 1s - loss: 1.0669e-07\n",
      "Epoch 78/100\n",
      " - 1s - loss: 1.0585e-07\n",
      "Epoch 79/100\n",
      " - 1s - loss: 1.0528e-07\n",
      "Epoch 80/100\n",
      " - 1s - loss: 1.0488e-07\n",
      "Epoch 81/100\n",
      " - 1s - loss: 1.0458e-07\n",
      "Epoch 82/100\n",
      " - 1s - loss: 1.0440e-07\n",
      "Epoch 83/100\n",
      " - 1s - loss: 1.0425e-07\n",
      "Epoch 84/100\n",
      " - 1s - loss: 1.0415e-07\n",
      "Epoch 85/100\n",
      " - 1s - loss: 1.0407e-07\n",
      "Epoch 86/100\n",
      " - 1s - loss: 1.0401e-07\n",
      "Epoch 87/100\n",
      " - 1s - loss: 1.0398e-07\n",
      "Epoch 88/100\n",
      " - 1s - loss: 1.0395e-07\n",
      "Epoch 89/100\n",
      " - 1s - loss: 1.0393e-07\n",
      "Epoch 90/100\n",
      " - 1s - loss: 1.0391e-07\n",
      "Epoch 91/100\n",
      " - 1s - loss: 1.0390e-07\n",
      "Epoch 92/100\n",
      " - 1s - loss: 1.0389e-07\n",
      "Epoch 93/100\n",
      " - 1s - loss: 1.0388e-07\n",
      "Epoch 94/100\n",
      " - 1s - loss: 1.0387e-07\n",
      "Epoch 95/100\n",
      " - 1s - loss: 1.0387e-07\n",
      "Epoch 96/100\n",
      " - 1s - loss: 1.0386e-07\n",
      "Epoch 97/100\n",
      " - 2s - loss: 1.0386e-07\n",
      "Epoch 98/100\n",
      " - 2s - loss: 1.0386e-07\n",
      "Epoch 99/100\n",
      " - 2s - loss: 1.0385e-07\n",
      "Epoch 100/100\n",
      " - 2s - loss: 1.0385e-07\n",
      "Accuracy of predicting floors =  0.8488169798190675\n",
      "--- Run time: 2.22 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the model\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, input_dim=521, activation='relu'))\n",
    "model_2.add(Dense(80, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(5, activation='softmax'))\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(\n",
    "    X_train2,\n",
    "    y_train2,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "predictions2 = np.round(model_2.predict(X_test2))\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy of predicting floors = \",accuracy_score(y_test2,predictions2))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy =  0.8284620737647878\n",
      "--- Run time: 2.22 mins ---\n"
     ]
    }
   ],
   "source": [
    "predictions = np.hstack((predictions1, predictions2)) \n",
    "y_test = np.hstack((y_test1, y_test2))  \n",
    "# accuracy\n",
    "print(\"Total Accuracy = \",accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 3s - loss: 0.0231\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0032\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0019\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0014\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0011\n",
      "Epoch 6/100\n",
      " - 1s - loss: 8.1361e-04\n",
      "Epoch 7/100\n",
      " - 1s - loss: 6.9446e-04\n",
      "Epoch 8/100\n",
      " - 1s - loss: 5.6776e-04\n",
      "Epoch 9/100\n",
      " - 1s - loss: 5.4293e-04\n",
      "Epoch 10/100\n",
      " - 1s - loss: 5.0378e-04\n",
      "Epoch 11/100\n",
      " - 1s - loss: 4.9295e-04\n",
      "Epoch 12/100\n",
      " - 1s - loss: 4.5074e-04\n",
      "Epoch 13/100\n",
      " - 1s - loss: 3.9059e-04\n",
      "Epoch 14/100\n",
      " - 1s - loss: 3.5785e-04\n",
      "Epoch 15/100\n",
      " - 1s - loss: 3.5069e-04\n",
      "Epoch 16/100\n",
      " - 1s - loss: 3.5783e-04\n",
      "Epoch 17/100\n",
      " - 1s - loss: 3.2465e-04\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.9517e-04\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.6478e-04\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.6751e-04\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.3837e-04\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.2372e-04\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.0705e-04\n",
      "Epoch 24/100\n",
      " - 2s - loss: 2.0446e-04\n",
      "Epoch 25/100\n",
      " - 1s - loss: 1.9677e-04\n",
      "Epoch 26/100\n",
      " - 1s - loss: 1.7678e-04\n",
      "Epoch 27/100\n",
      " - 1s - loss: 1.6693e-04\n",
      "Epoch 28/100\n",
      " - 1s - loss: 1.4927e-04\n",
      "Epoch 29/100\n",
      " - 1s - loss: 1.5042e-04\n",
      "Epoch 30/100\n",
      " - 1s - loss: 1.5505e-04\n",
      "Epoch 31/100\n",
      " - 1s - loss: 1.7259e-04\n",
      "Epoch 32/100\n",
      " - 1s - loss: 1.3269e-04\n",
      "Epoch 33/100\n",
      " - 1s - loss: 1.1612e-04\n",
      "Epoch 34/100\n",
      " - 1s - loss: 1.1331e-04\n",
      "Epoch 35/100\n",
      " - 1s - loss: 1.0156e-04\n",
      "Epoch 36/100\n",
      " - 1s - loss: 1.0115e-04\n",
      "Epoch 37/100\n",
      " - 1s - loss: 1.0309e-04\n",
      "Epoch 38/100\n",
      " - 2s - loss: 1.1143e-04\n",
      "Epoch 39/100\n",
      " - 2s - loss: 9.4726e-05\n",
      "Epoch 40/100\n",
      " - 2s - loss: 8.5940e-05\n",
      "Epoch 41/100\n",
      " - 2s - loss: 8.1206e-05\n",
      "Epoch 42/100\n",
      " - 2s - loss: 8.1220e-05\n",
      "Epoch 43/100\n",
      " - 2s - loss: 7.9599e-05\n",
      "Epoch 44/100\n",
      " - 2s - loss: 8.4931e-05\n",
      "Epoch 45/100\n",
      " - 2s - loss: 7.3387e-05\n",
      "Epoch 46/100\n",
      " - 2s - loss: 7.3190e-05\n",
      "Epoch 47/100\n",
      " - 2s - loss: 7.2053e-05\n",
      "Epoch 48/100\n",
      " - 1s - loss: 6.8877e-05\n",
      "Epoch 49/100\n",
      " - 1s - loss: 7.1943e-05\n",
      "Epoch 50/100\n",
      " - 1s - loss: 6.6980e-05\n",
      "Epoch 51/100\n",
      " - 2s - loss: 6.9509e-05\n",
      "Epoch 52/100\n",
      " - 1s - loss: 5.9012e-05\n",
      "Epoch 53/100\n",
      " - 1s - loss: 5.7703e-05\n",
      "Epoch 54/100\n",
      " - 2s - loss: 5.4717e-05\n",
      "Epoch 55/100\n",
      " - 2s - loss: 5.3001e-05\n",
      "Epoch 56/100\n",
      " - 2s - loss: 5.2153e-05\n",
      "Epoch 57/100\n",
      " - 2s - loss: 5.4228e-05\n",
      "Epoch 58/100\n",
      " - 1s - loss: 4.7827e-05\n",
      "Epoch 59/100\n",
      " - 1s - loss: 4.3708e-05\n",
      "Epoch 60/100\n",
      " - 1s - loss: 4.7193e-05\n",
      "Epoch 61/100\n",
      " - 1s - loss: 4.5308e-05\n",
      "Epoch 62/100\n",
      " - 1s - loss: 4.6344e-05\n",
      "Epoch 63/100\n",
      " - 2s - loss: 4.5879e-05\n",
      "Epoch 64/100\n",
      " - 2s - loss: 4.3103e-05\n",
      "Epoch 65/100\n",
      " - 2s - loss: 4.2831e-05\n",
      "Epoch 66/100\n",
      " - 2s - loss: 3.9821e-05\n",
      "Epoch 67/100\n",
      " - 2s - loss: 4.0598e-05\n",
      "Epoch 68/100\n",
      " - 2s - loss: 3.9461e-05\n",
      "Epoch 69/100\n",
      " - 2s - loss: 3.8081e-05\n",
      "Epoch 70/100\n",
      " - 2s - loss: 3.8277e-05\n",
      "Epoch 71/100\n",
      " - 1s - loss: 4.2363e-05\n",
      "Epoch 72/100\n",
      " - 1s - loss: 3.8285e-05\n",
      "Epoch 73/100\n",
      " - 1s - loss: 3.6479e-05\n",
      "Epoch 74/100\n",
      " - 1s - loss: 3.2943e-05\n",
      "Epoch 75/100\n",
      " - 1s - loss: 3.5062e-05\n",
      "Epoch 76/100\n",
      " - 1s - loss: 3.3954e-05\n",
      "Epoch 77/100\n",
      " - 1s - loss: 3.1786e-05\n",
      "Epoch 78/100\n",
      " - 1s - loss: 3.0318e-05\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.7507e-05\n",
      "Epoch 80/100\n",
      " - 1s - loss: 2.9796e-05\n",
      "Epoch 81/100\n",
      " - 1s - loss: 3.0064e-05\n",
      "Epoch 82/100\n",
      " - 2s - loss: 3.2269e-05\n",
      "Epoch 83/100\n",
      " - 1s - loss: 3.1132e-05\n",
      "Epoch 84/100\n",
      " - 1s - loss: 3.0996e-05\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.9188e-05\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.5942e-05\n",
      "Epoch 87/100\n",
      " - 1s - loss: 2.4098e-05\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.5574e-05\n",
      "Epoch 89/100\n",
      " - 2s - loss: 2.8405e-05\n",
      "Epoch 90/100\n",
      " - 2s - loss: 2.5294e-05\n",
      "Epoch 91/100\n",
      " - 2s - loss: 2.4637e-05\n",
      "Epoch 92/100\n",
      " - 2s - loss: 2.5138e-05\n",
      "Epoch 93/100\n",
      " - 2s - loss: 2.5998e-05\n",
      "Epoch 94/100\n",
      " - 2s - loss: 2.4140e-05\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.2010e-05\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.5747e-05\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.5697e-05\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.3387e-05\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.0453e-05\n",
      "Epoch 100/100\n",
      " - 1s - loss: 1.8071e-05\n",
      "RMSE of predicting LONGTITUDE =  17.315640705505697\n",
      "--- Run time: 2.43 mins ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Define the model\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(50, input_dim=523, activation='relu'))\n",
    "model_3.add(Dense(80, activation='relu'))\n",
    "model_3.add(Dense(50, activation='relu'))\n",
    "model_3.add(Dense(1, activation='linear'))\n",
    "model_3.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model_3.fit(\n",
    "    X_train3,\n",
    "    y_train3,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "predictions3 = (model_3.predict(X_test3))\n",
    "\n",
    "# accuracy\n",
    "print(\"RMSE of predicting LONGTITUDE = \", mean_squared_error(y_test3[:,0]*1000,predictions3[:,0]*1000)**(0.5) )\n",
    "#print(\"Accuracy of predicting LATITUDE = \", mean_squared_error(y_test3[:,1],predictions3[:,1]))\n",
    "\n",
    "\n",
    "print(\"--- Run time: %s mins ---\" % np.round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
